# Machine Learning from Standford University by Andrew Ng on Coursera.

## Outline:
### M1: Introduction.
- What is Machine Learning?
- Supervised Learning.
- Unsupervised Learning.
- Real World Applications.
- Supervised Learning Examples.

### M2: Linear Regression with One Variable.
- Model Representation.
    - Hypothesis Function.
    - Cost Function.
- Gradient Descent.
    - Gradient Descent Intuition.
    - Gradient Descent Algorithm.
    - Gradient Descent for Linear Regression.

### M3: Linear Algebra Review.
- Matrices and Vectors.
- Matrix Addition and Substraction.
- Matrix Multiplication.
    - Scalar Multiplication.
    - Matrix Vector Multiplication.
    - Matrix Matrix Multiplication.
    - Matrix Multiplication Properties.
- Inverse and Transpose.

### M4: Linear Regression with Multiple Variables.
- Multivariate Linear Regression.
    - Multiple Features.
    - Gradient Descent for Multiple Variables.
    - Features Scaling.
    - Learning Rate.
    - Features and Polynomimal Regression.
- Computing Parameters Analytically.
    - Normal Equation.
    - Normal Equation Noninvertibility.

### M5: Octave/Matlab Tutorial.
- Basic Operations.
- Moving Data Around.
- Computing on Data.
- Plotting Data.
- Control Statements.
- Vectorization.
- Functions.
- Debugging.
- Advanced Octave/Matlab Features.

### M6: Logistic Regression.
- Classification and Representation.
    - Classification.
    - Hypothesis Representation.
    - Decision Boundary.
- Logistic Regression Model.
    - Cost Function.
    - Simplified Cost Function and Gradient Descent.
    - Advanced Optimization.
- Multiclass Classification.
    - Multiclass Classification: One-vs-all, Softmax Regression.
    
### M7: Regularization.
- Solving the Problem of Overfitting.
- Cost Function.
- Regularized Linear Regression.
- Regularized Logistic Regression.

### M8: Neural Networks: Representation.
- Motivations for using neural networks
- Neural Networks
- Applications.

### M9: Neural Networks: Learning.
- Cost Function.
- Backpropagation Algorithm.
- Backpropagation Intuition.
- Gradient Checking.
- Random Initialization.
- Putting it all Together.
- Neural Network in Practice: Autonomous Driving.
- Advanced Optimization.

### M10: Advice for Applying Machine Learning.
- Deciding What to Try Next.
- Evaluating a Hypothesis.
- Model Selection and Train/Validation/Test Sets.
- Diagnosing Bias vs. Variance.
- Regularization and Bias/Variance.
- Learning Curves.
- Deciding What to Do Next Revisited.

### M11: Machine Learning System Design.
- Prioritizing What to Work On.
- Error Analysis.
- Error Metrics for Skewed Classes.
- Trading off Precision and Recall.
- Data for Machine Learning.

### M12: Support Vector Machines.
- Optimization Objective.
- Large Margin Intuition.
- Kernels I.
- Kernels II.
- Using an SVM.

### M13: Unsupervised Learning.
- Unsupervised Learning: Introduction.
- K-Means Algorithm.
- Optimization Objective.
- Random Initialization.
- Choosing the Number of Clusters.
- Choosing the Number of Clusters: Elbow Method.

### M14: Dimensionality Reduction.
- Motivation I: Data Compression.
- Motivation II: Data Visualization.
- Principal Component Analysis Problem Formulation.
- Principal Component Analysis Algorithm.
- Reconstruction from Compressed Representation.
- Choosing the Number of Principal Components.
- Advice for Applying PCA.

### M15: Anomaly Detection.
- Problem Motivation.
- Gaussian Distribution.
- Algorithm.
- Developing and Evaluating an Anomaly Detection System.
- Anomaly Detection vs. Supervised Learning.
- Multivariate Gaussian Distribution.
- Anomaly Detection using the Multivariate Gaussian Distribution.

### M16: Recommender Systems.
- Problem Formulation.
- Content-Based Recommendations.
- Collaborative Filtering Algorithm.
- Vectorization: Low Rank Matrix Factorization.
- Implementation Detail: Mean Normalization.

### M17: Large Scale Machine Learning.
- Learning with Large Datasets.
- Stochastic Gradient Descent.
- Mini-Batch Gradient Descent.
- Stochastic Gradient Descent Convergence.
- Online Learning.
- Map Reduce and Data Parallelism.

### M18: Application Example: Photo OCR.
- Problem Description and Pipeline.
- Sliding Windows.
- Getting Lots of Data and Artificial Data.
- Ceiling Analysis: What part of the pipeline to work on next.


--- The End ---