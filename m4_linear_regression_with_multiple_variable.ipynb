{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e932122b",
   "metadata": {},
   "source": [
    "# Linear Regression with Multiple Variables.\n",
    "\n",
    "## Multivariate Linear Regression.\n",
    "### Multiple Features.\n",
    "- Linear regression with multiple variables is also known as `multivariate linear regression`.\n",
    "- We now introduce notation for equations where we can have any number of input variables.\n",
    "\n",
    "$$\n",
    "x_j^{(i)}=value\\ of\\ feature\\ j\\ in\\ the\\ i^{th}\\ training\\ example.\\\\\n",
    "x^{(i)}=the\\ input\\ (features)\\ of\\ the\\ i^{(th)}\\ training\\ example.\\\\\n",
    "m=the\\ number\\ of\\ training examples.\\\\\n",
    "n=the\\ number\\ of\\ features.\\\\\n",
    "$$\n",
    "\n",
    "The multivariable form of the pypothesis function accommodating these multiple features is as follows:\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\dots+\\theta_nx_n\n",
    "$$\n",
    "\n",
    "In order to develop intuition about this function, we can think about $\\theta_0$ as the basic price of a house, $\\theta_1$ as the price per spare meter, $\\theta_2$ as the price per floor, etc. $x_1$ will be the number of spare meters in the house, $x_2$ the number of floors, etc.\n",
    "\n",
    "Using the definition of matric multiplication, our multivariable hypothesis function can be concisely represented as:\n",
    "\n",
    "$$\n",
    "h_\\theta(x)=[\\theta_0\\    \\theta_1\\    ...\\    \\theta_n]\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{bmatrix}\n",
    "=\\theta^Tx\n",
    "$$\n",
    "\n",
    "This is a vectorization of our hypothesis function for one training example; see the lession on vectorization to learn more.\n",
    "\n",
    "Remark: Note that for convenience reasons in this course we assume $x_0^{(i)}=1\\ for\\ (i\\in1,\\dots,m)$. This allow us to do matrix operations with theta $\\theta$ and x. Hence making the two vectors $\\theta$ and $x^(i)$ match each other element-wise (that is, have the same number of elements: n+1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca2970",
   "metadata": {},
   "source": [
    "#### Question\n",
    "When there are n features, we define the coust function as:\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\n",
    "$$\n",
    "\n",
    "For linear regression, which of the following are also equivalent and correct definitions of $J(\\theta)$?\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}()\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def66ca3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
